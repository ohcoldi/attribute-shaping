{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861defe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79e0a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('result_data.csv')\n",
    "Разобъём набор данных таким образом, как это рекомендовано согласно документации Sklearn. А именно 30 на 70. Как представленно в описании, такая выборка является оптимальной, поскольку абсолютное большинство данных должно находится при обучении модели, чтобы получить наиболее оптимизированную модель со стороны её точности\n",
    "\n",
    "Стратификация\n",
    "При разделении стратифицируем данные, чтобы получить одинаковую в процентом соотношении выборку, чтобы не было перевеса на какой-то один класс и такая ситуация не повлияла на некорректное обучение модели\n",
    "\n",
    "df\n",
    "\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "df=df[df['Rt']<5].reset_index(drop=True)\n",
    "Определение переменной опасности\n",
    "df1=df[df['Rt']<=0.7]\n",
    "df1['Danger']=0\n",
    "\n",
    "df2=df[(df['Rt']>0.7) & (df['Rt']<=0.95)]\n",
    "df2['Danger']=1\n",
    "\n",
    "df3=df[df['Rt']>0.95]\n",
    "df3['Danger']=2\n",
    "\n",
    "df=pd.concat([df1, df2, df3]).reset_index(drop=True)\n",
    "\n",
    "X=df[['new_cases', 'new_deaths', 'Rt']]\n",
    "y=df['Danger']\n",
    "\n",
    "#Получение выборок\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab0d3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ассмотрим три модели классификации\n",
    "\n",
    "KNeighborsClassifier\n",
    "Классификация на основе соседей - это тип обучения на основе экземпляров или необобщающего обучения: он не пытается построить общую внутреннюю модель, а просто сохраняет экземпляры обучающих данных. Классификация вычисляется простым большинством голосов ближайших соседей каждой точки: точке запроса назначается класс данных, который имеет наибольшее количество представителей среди ближайших соседей точки.\n",
    "\n",
    "RandomForestClassifier\n",
    "Случайный лес — это метаоценка, которая соответствует ряду классификаторов дерева решений для различных подвыборок набора данных и использует усреднение для повышения точности прогнозирования и контроля переобучения. Размер подвыборки управляется параметром max_samples, если bootstrap=True (по умолчанию), в противном случае для построения каждого дерева используется весь набор данных\n",
    "\n",
    "GaussianNB\n",
    "Наи́вный ба́йесовский классифика́тор — простой вероятностный классификатор, основанный на применении теоремы Байеса со строгими (наивными) предположениями о независимости. В зависимости от точной природы вероятностной модели, наивные байесовские классификаторы могут обучаться очень эффективно\n",
    "\n",
    "Матрикики\n",
    "Рассмотрим две метрикики для оценивания модели классификации\n",
    "\n",
    "accuracy f1-score\n",
    "Это гармоническое среднее значений точности и полноты. Возьмём её, потому что она дает лучшую оценку неправильно классифицированных случаев\n",
    "\n",
    "macro avg f1-score\n",
    "macro avg f1-score пожалуй, самый простой из многочисленных методов усреднения. Макроусредненная оценка F1 (или макрооценка F1) вычисляется путем взятия среднего арифметического (также известного как невзвешенное среднее) всех оценок F1 для каждого класса. Этот метод будет взят, поскольку он обрабатывает все классы одинаково, независимо от их значений поддержки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e9d31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Импорт моделей\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "#Обучение\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "neigh.fit(X_train, y_train)\n",
    "preds=neigh.predict(X_test)\n",
    "print(classification_report(preds, y_test))\n",
    "\n",
    "#Обучение\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_train, y_train)\n",
    "rfc_preds=rfc.predict(X_test)\n",
    "print(classification_report(rfc_preds, y_test))\n",
    "\n",
    "#Обучение\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "gnb_preds=gnb.predict(X_test)\n",
    "print(classification_report(gnb_preds, y_test))\n",
    "\n",
    "Вывод\n",
    "Наиболее оптимальной моделью будет KNeighborsClassifier c accuracy f1-score = 0.78 и macro avg f1-score = 0.74, поскольку по сравнению с другими он показал наилучший результат. RandomForestClassifier не будет взят, поскольку у него явное переобучение\n",
    "\n",
    "Отчёт\n",
    "2.1 Разбиение набора данных - набор данныхз разбит на обучаюшую и тестовую выборки\n",
    "2.3 Классификация - выбраны 3 алгоритма классификации\n",
    "2.4 Обучение - произведена классификация по уровню опасности\n",
    "\n",
    "# Сохранение данных\n",
    "df.to_csv('result_data.csv', encoding='utf-8-sig', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bdef9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "1 Разбиение набора данных\n",
    "Разделите исходный набор данных на обучающую и тестирующую выборки оптимальным образом. Приведите обоснование разбиения\n",
    "2 Визуализация зависимостей данных\n",
    "Используя программные средства, визуализируйте зависимости атрибутов в наборе данных.  Визуализация должна отражать влияние атрибутов на определение классов – уровня опасности посещения страны для туриста. Произведите расчеты зависимостей по выбранным алгоритмам. Приведите интерпретацию полученным результатам\n",
    "3 Классификация исходных компетенций\n",
    "Выберите модель классификации данных по уровням опасности посещения для туристов. Приведите обоснование выбора модели. \n",
    "4 Обучение\n",
    "Проведите обучение выбранной модели на обучающей выборке. Протестируйте работу обученной модели на тестовой выборке. Определите показатели точности работы выбранной модели, сравните с остальными рассматриваемыми моделями.\n",
    "5 Feature Engineering\n",
    "Путём преобразования набора данных, добейтесь более точной работы выбранной модели. Опишите приемы генерации новых данных и результаты, к которым они привели, рассматривая все ранее определенные показатели точности \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70161f73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b16a92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84dc0bc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e30b1a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279505c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
